{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sahana Thoravalli Prabhuswamy\n",
        "\n",
        "# Deep Learning Assignment - 13\n",
        "\n",
        "# Github link\n",
        "\n",
        "https://github.com/SahanaTP/DeepLearningAssignments"
      ],
      "metadata": {
        "id": "jJdTGyZao7pP"
      },
      "id": "jJdTGyZao7pP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing required libraries\n",
        "\n",
        "**Gymnsium provides rich python libraries for Reinforcement Learning. It has pre-built environment and provides a means for the agent, learning algorithm and the environment to communicate.**"
      ],
      "metadata": {
        "id": "sMz56RRJTzIY"
      },
      "id": "sMz56RRJTzIY"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install swig"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBk7KEcTNYtF",
        "outputId": "c8bacba2-1a1d-4f81-9d5f-90f035fb0899"
      },
      "id": "RBk7KEcTNYtF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting swig\n",
            "  Using cached swig-4.2.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n",
            "Installing collected packages: swig\n",
            "Successfully installed swig-4.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Dlwj8ekND6F",
        "outputId": "d7faa840-6d74-4b18-f4b0-4250e6db8ee6"
      },
      "id": "1Dlwj8ekND6F",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/953.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/953.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.11.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Box 2d enviroment has 3 RL game environments and one of them is lunar lander**"
      ],
      "metadata": {
        "id": "S-SHBHTBVn2v"
      },
      "id": "S-SHBHTBVn2v"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium[box2d]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGwllhTBNNyC",
        "outputId": "ded61df0-7ffc-4955-92a4-dcdd7fadaabc"
      },
      "id": "fGwllhTBNNyC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.11.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (0.0.4)\n",
            "Collecting box2d-py==2.3.5 (from gymnasium[box2d])\n",
            "  Using cached box2d-py-2.3.5.tar.gz (374 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.5.2)\n",
            "Requirement already satisfied: swig==4.* in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.2.1)\n",
            "Building wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp310-cp310-linux_x86_64.whl size=2376101 sha256=d4f1e9ec850755896c1209b01f0329f9933b509b77ab782fcc27bc2ecc5d993b\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/8f/6a/eaaadf056fba10a98d986f6dce954e6201ba3126926fc5ad9e\n",
            "Successfully built box2d-py\n",
            "Installing collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install dill"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uoaWGBXN4pR",
        "outputId": "49c2bd1c-621d-4abb-f8b3-8711732f8a8f"
      },
      "id": "7uoaWGBXN4pR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dill\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dill\n",
            "Successfully installed dill-0.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The basic components of RL are:**\n",
        "\n",
        "\n",
        "1. Agent - Autonomous decision making entity which interacts with the environment to achieve a goal\n",
        "2. Environment - external entity or context that interacts with agents with rewards or punishments\n",
        "3. State - Different stages an agent can go to\n",
        "4. Reward - extra points earned by the agent by taking the right steps\n",
        "5. terminal - final state\n",
        "\n",
        "The lunar lander environment facilitates the agent to make 4 descrete actions:\n",
        "\n",
        "1. do nothing\n",
        "2. fire left orientation engine\n",
        "3. fire main engine\n",
        "4. fire right orientation engine\n",
        "\n",
        "\n",
        "* Q - learning is an off-policy, model free, value based algorithm that will predict best series of actions based on the current state of the agent.\n",
        "\n",
        "* Q refers to the quality of the reward abtained for the given state and action.\n",
        "\n",
        "* Here a neural network is used as a function approximator i.e. two deep neural networks(Agent and DoubleQAgent) one to predict the actions and other to predict/learn the Q values.\n",
        "\n",
        "* In the following code a memory buffer is used to store the state, action, reward, new_state and terminal state and to provide a batch of random samples of there parameters.\n",
        "\n",
        "* This second neural network has the same shape and architecture as the one used for the action-selection and is periodically updated with the weights of the action-selection network.\n",
        "\n",
        "* Parameters used for training both the DQNs:\n",
        "\n",
        "gamma=0.99, epsilon=1.0, batch_size=128, lr=0.001,\n",
        "epsilon_dec=0.996, epsilon_end=0.01, mem_size=1000000\n",
        "\n",
        "alpha  = learning rate (α) used by the DQN implementation\n",
        "\n",
        "gamma = discount factor (γ) of future rewards, A smaller gamma value of 0.9 will be faster but will prevent the agent from properly crediting success after 10 steps in the future (1/(1-γ) = 1/(1-0.9) = 10) while a large value like γ = 0.999 will allow the agent to look all the way to 1,000 actions in the future (1/(1-γ) = 1/(1-0.999) = 1000) but will be slow to converge or learn. Hence, an in between value of 0.99 is chosen to consider 100 steps in the future.\n",
        "\n",
        "epsilon = the decay rate of ε (ε-decay) to establish proper exploitation versus exploration balance.\n",
        "\n",
        "epsilon_dec = decrement of epsilon for larger spaces, a decay rate of 0.996 will initially give importance to more exploration and in later stages gives more importance to exploitation\n",
        "\n",
        "* The next Q value is updated using the formula:\n",
        "q_updated = rewards + gamma * q_next * (1 - terminals)\n",
        "\n",
        "\n",
        "* An episode is considered a solution if it scores at least 200 points. Different points are assigned for different actions and a -100/ 100 pointis received for crashing or reaching the goal\n",
        "\n",
        "* Both exploitation and exploration features are used to reach the goal(200 points)\n",
        "\n"
      ],
      "metadata": {
        "id": "joXhYtIVWQPx"
      },
      "id": "joXhYtIVWQPx"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import collections # For dequeue for the memory buffer\n",
        "import random\n",
        "import dill as pickle # For storing the buffer state\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class MemoryBuffer(object):\n",
        "    def __init__(self, max_size):\n",
        "        self.memory_size = max_size\n",
        "        self.trans_counter=0 # num of transitions in the memory\n",
        "                             # this count is required to delay learning\n",
        "                             # until the buffer is sensibly full\n",
        "        self.index=0         # current pointer in the buffer\n",
        "        self.buffer = collections.deque(maxlen=self.memory_size)\n",
        "        self.transition = collections.namedtuple(\"Transition\", field_names=[\"state\", \"action\", \"reward\", \"new_state\", \"terminal\"])\n",
        "\n",
        "\n",
        "    def save(self, state, action, reward, new_state, terminal):\n",
        "        t = self.transition(state, action, reward, new_state, terminal)\n",
        "        self.buffer.append(t)\n",
        "        self.trans_counter = (self.trans_counter + 1) % self.memory_size\n",
        "\n",
        "    def random_sample(self, batch_size):\n",
        "        assert len(self.buffer) >= batch_size # should begin sampling only when sufficiently full\n",
        "        transitions = random.sample(self.buffer, k=batch_size) # number of transitions to sample\n",
        "        states = torch.from_numpy(np.vstack([e.state for e in transitions if e is not None])).float().to(device)\n",
        "        actions = torch.from_numpy(np.vstack([e.action for e in transitions if e is not None])).long().to(device)\n",
        "        rewards = torch.from_numpy(np.vstack([e.reward for e in transitions if e is not None])).float().to(device)\n",
        "        new_states = torch.from_numpy(np.vstack([e.new_state for e in transitions if e is not None])).float().to(device)\n",
        "        terminals = torch.from_numpy(np.vstack([e.terminal for e in transitions if e is not None]).astype(np.uint8)).float().to(device)\n",
        "\n",
        "        return states, actions, rewards, new_states, terminals\n",
        "\n",
        "class QNN(nn.Module):\n",
        "    def __init__(self, state_size, action_size, seed):\n",
        "        super(QNN, self).__init__()\n",
        "        self.seed = torch.manual_seed(seed)\n",
        "        self.fc1 = nn.Linear(state_size, 128)\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, action_size)\n",
        "\n",
        "    def forward(self, state):\n",
        "        x = self.fc1(state)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        return self.fc3(x)\n",
        "\n",
        "class Agent(object):\n",
        "    def __init__(self, gamma=0.99, epsilon=1.0, batch_size=128, lr=0.001,\n",
        "                 epsilon_dec=0.996,  epsilon_end=0.01,\n",
        "                 mem_size=1000000):\n",
        "        self.gamma = gamma # alpha = learn rate, gamma = discount\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_dec = epsilon_dec # decrement of epsilon for larger spaces\n",
        "        self.epsilon_min = epsilon_end\n",
        "        self.batch_size = batch_size\n",
        "        self.memory = MemoryBuffer(mem_size)\n",
        "\n",
        "    def save(self, state, action, reward, new_state, done):\n",
        "        # self.memory.trans_counter += 1\n",
        "        self.memory.save(state, action, reward, new_state, done)\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        # state = state[np.newaxis, :]\n",
        "        rand = np.random.random()\n",
        "        state = torch.from_numpy(state).float().unsqueeze(0)\n",
        "        self.q_func.eval()\n",
        "        with torch.no_grad():\n",
        "            action_values = self.q_func(state)\n",
        "        self.q_func.train()\n",
        "        # print(state)\n",
        "        if rand > self.epsilon:\n",
        "            return np.argmax(action_values.cpu().data.numpy())\n",
        "        else:\n",
        "            # exploring: return a random action\n",
        "            return np.random.choice([i for i in range(4)])\n",
        "\n",
        "    def reduce_epsilon(self):\n",
        "        self.epsilon = self.epsilon*self.epsilon_dec if self.epsilon > \\\n",
        "                       self.epsilon_min else self.epsilon_min\n",
        "\n",
        "    def learn(self):\n",
        "        raise Exception(\"Not implemented\")\n",
        "\n",
        "    def save_model(self, path):\n",
        "        torch.save(self.q_func.state_dict(), path)\n",
        "\n",
        "    def load_saved_model(self, path):\n",
        "        self.q_func = QNN(8, 4, 42).to(device)\n",
        "        self.q_func.load_state_dict(torch.load(path))\n",
        "        self.q_func.eval()\n",
        "\n",
        "\n",
        "class DoubleQAgent(Agent):\n",
        "    def __init__(self, gamma=0.99, epsilon=1.0, batch_size=128, lr=0.001,\n",
        "                 epsilon_dec=0.996,  epsilon_end=0.01,\n",
        "                 mem_size=1000000, replace_q_target = 100):\n",
        "\n",
        "        super().__init__(lr=lr, gamma=gamma, epsilon=epsilon, batch_size=batch_size,\n",
        "             epsilon_dec=epsilon_dec,  epsilon_end=epsilon_end,\n",
        "             mem_size=mem_size)\n",
        "\n",
        "        self.replace_q_target = replace_q_target\n",
        "        self.q_func = QNN(8, 4, 42).to(device)\n",
        "        self.q_func_target = QNN(8, 4, 42).to(device)\n",
        "        self.optimizer = optim.Adam(self.q_func.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "    def learn(self):\n",
        "        if self.memory.trans_counter < self.batch_size: # wait before you start learning\n",
        "            return\n",
        "\n",
        "        # 1. Choose a sample from past transitions:\n",
        "        states, actions, rewards, new_states, terminals = self.memory.random_sample(self.batch_size)\n",
        "\n",
        "        # 2. Update the target values\n",
        "        q_next = self.q_func_target(new_states).detach().max(1)[0].unsqueeze(1)\n",
        "        q_updated = rewards + self.gamma * q_next * (1 - terminals)\n",
        "        q = self.q_func(states).gather(1, actions)\n",
        "\n",
        "        # 3. Update the main NN\n",
        "        loss = F.mse_loss(q, q_updated)\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        # 4. Update the target NN (every N-th step)\n",
        "        if self.memory.trans_counter % self.replace_q_target == 0: # wait before you start learning\n",
        "            for target_param, local_param in zip(self.q_func_target.parameters(), self.q_func.parameters()):\n",
        "                target_param.data.copy_(local_param.data)\n",
        "\n",
        "        # 5. Reduce the exploration rate\n",
        "        self.reduce_epsilon()\n",
        "\n",
        "\n",
        "\n",
        "    def save_model(self, path):\n",
        "        super().save_model(path)\n",
        "        torch.save(self.q_func.state_dict(), path+'.target')\n",
        "\n",
        "\n",
        "    def load_saved_model(self, path):\n",
        "        super().load_saved_model(path)\n",
        "        self.q_func_target = QNN(8, 4, 42).to(device)\n",
        "        self.q_func_target.load_state_dict(torch.load(path+'.target'))\n",
        "        self.q_func_target.eval()\n",
        "\n"
      ],
      "metadata": {
        "id": "YDYkjE1_NCFA"
      },
      "id": "YDYkjE1_NCFA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9184d259-bfe0-4ad8-a43e-8bce502059c8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-07T21:22:21.755198Z",
          "iopub.status.busy": "2023-02-07T21:22:21.755051Z",
          "iopub.status.idle": "2023-02-07T21:22:23.585329Z",
          "shell.execute_reply": "2023-02-07T21:22:23.584743Z",
          "shell.execute_reply.started": "2023-02-07T21:22:21.755181Z"
        },
        "tags": [],
        "id": "9184d259-bfe0-4ad8-a43e-8bce502059c8"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import json # for dumping debug data\n",
        "import time # for benchmarking\n",
        "import numpy as np\n",
        "\n",
        "LEARN_EVERY = 4\n",
        "def train_agent(n_episodes=2000, load_latest_model=False):\n",
        "    print(\"Training a DDQN agent on {} episodes. Pretrained model = {}\".format(n_episodes,load_latest_model))\n",
        "    env = gym.make(\"LunarLander-v2\")\n",
        "    agent = DoubleQAgent(gamma=0.99, epsilon=1.0, epsilon_dec=0.995, lr=0.001, mem_size=200000, batch_size=128, epsilon_end=0.01)\n",
        "    if load_latest_model:\n",
        "        agent.load_saved_model('ddqn_torch_model.h5')\n",
        "        print('Loaded most recent: ddqn_torch_model.h5')\n",
        "\n",
        "    scores = []\n",
        "    eps_history = []\n",
        "    start = time.time()\n",
        "    for i in range(n_episodes):\n",
        "        terminated = False\n",
        "        truncated = False\n",
        "        score = 0\n",
        "        state = env.reset()[0]\n",
        "        steps = 0\n",
        "        while not (terminated or truncated):\n",
        "            action = agent.choose_action(state)\n",
        "            new_state, reward, terminated, truncated, info = env.step(action)\n",
        "            agent.save(state, action, reward, new_state, terminated)\n",
        "            state = new_state\n",
        "            if steps > 0 and steps % LEARN_EVERY == 0:\n",
        "                agent.learn()\n",
        "            steps += 1\n",
        "            score += reward\n",
        "\n",
        "        eps_history.append(agent.epsilon)\n",
        "        scores.append(score)\n",
        "        avg_score = np.mean(scores[max(0, i-100):(i+1)])\n",
        "\n",
        "        if (i+1) % 10 == 0 and i > 0:\n",
        "            # Report expected time to finish the training\n",
        "            print('Episode {} in {:.2f} min. Expected total time for {} episodes: {:.0f} min. [{:.2f}/{:.2f}]'.format((i+1),\n",
        "                                                                                                                      (time.time() - start)/60,\n",
        "                                                                                                                      n_episodes,\n",
        "                                                                                                                      (((time.time() - start)/i)*n_episodes)/60,\n",
        "                                                                                                                      score,\n",
        "                                                                                                                      avg_score))\n",
        "\n",
        "        if (i+1) % 100 == 0 and i > 0:\n",
        "            # Save the model every N-th step just in case\n",
        "            agent.save_model('ddqn_torch_model.h5')\n",
        "            with open(\"ddqn_torch_dqn_scores_{}.json\".format(int(time.time())), \"w\") as fp:\n",
        "                json.dump(scores, fp)\n",
        "            with open(\"ddqn_torch_eps_history_{}.json\".format(int(time.time())), \"w\") as fp:\n",
        "                json.dump(eps_history, fp)\n",
        "\n",
        "    return agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "611f905c-9a67-4de9-a351-be3003b9f26b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-07T21:22:23.587161Z",
          "iopub.status.busy": "2023-02-07T21:22:23.586690Z",
          "iopub.status.idle": "2023-02-07T21:22:23.589493Z",
          "shell.execute_reply": "2023-02-07T21:22:23.589027Z",
          "shell.execute_reply.started": "2023-02-07T21:22:23.587140Z"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "611f905c-9a67-4de9-a351-be3003b9f26b",
        "outputId": "e282439b-c6ed-40da-c805-aa623f2dfb23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training a DDQN agent on 1500 episodes. Pretrained model = False\n",
            "Episode 10 in 0.03 min. Expected total time for 1500 episodes: 4 min. [-101.19/-208.35]\n",
            "Episode 20 in 0.07 min. Expected total time for 1500 episodes: 6 min. [-58.09/-166.79]\n",
            "Episode 30 in 0.15 min. Expected total time for 1500 episodes: 8 min. [-52.83/-174.55]\n",
            "Episode 40 in 0.31 min. Expected total time for 1500 episodes: 12 min. [-252.44/-167.49]\n",
            "Episode 50 in 0.45 min. Expected total time for 1500 episodes: 14 min. [-148.08/-153.60]\n",
            "Episode 60 in 0.55 min. Expected total time for 1500 episodes: 14 min. [-107.01/-149.11]\n",
            "Episode 70 in 0.70 min. Expected total time for 1500 episodes: 15 min. [-85.65/-144.03]\n",
            "Episode 80 in 0.93 min. Expected total time for 1500 episodes: 18 min. [-72.27/-138.18]\n",
            "Episode 90 in 1.20 min. Expected total time for 1500 episodes: 20 min. [-7.90/-128.91]\n",
            "Episode 100 in 1.57 min. Expected total time for 1500 episodes: 24 min. [-37.35/-119.70]\n",
            "Episode 110 in 1.84 min. Expected total time for 1500 episodes: 25 min. [-34.28/-101.18]\n",
            "Episode 120 in 2.16 min. Expected total time for 1500 episodes: 27 min. [14.45/-89.79]\n",
            "Episode 130 in 2.44 min. Expected total time for 1500 episodes: 28 min. [6.63/-72.31]\n",
            "Episode 140 in 2.66 min. Expected total time for 1500 episodes: 29 min. [-22.81/-64.57]\n",
            "Episode 150 in 2.88 min. Expected total time for 1500 episodes: 29 min. [-46.27/-54.71]\n",
            "Episode 160 in 3.19 min. Expected total time for 1500 episodes: 30 min. [-53.60/-43.70]\n",
            "Episode 170 in 3.50 min. Expected total time for 1500 episodes: 31 min. [1.42/-34.30]\n",
            "Episode 180 in 3.74 min. Expected total time for 1500 episodes: 31 min. [-154.90/-25.50]\n",
            "Episode 190 in 4.03 min. Expected total time for 1500 episodes: 32 min. [-19.47/-21.85]\n",
            "Episode 200 in 4.30 min. Expected total time for 1500 episodes: 32 min. [189.23/-12.11]\n",
            "Episode 210 in 4.51 min. Expected total time for 1500 episodes: 32 min. [249.39/7.48]\n",
            "Episode 220 in 4.73 min. Expected total time for 1500 episodes: 32 min. [152.13/19.70]\n",
            "Episode 230 in 4.96 min. Expected total time for 1500 episodes: 33 min. [172.25/35.07]\n",
            "Episode 240 in 5.10 min. Expected total time for 1500 episodes: 32 min. [-4.90/44.71]\n",
            "Episode 250 in 5.25 min. Expected total time for 1500 episodes: 32 min. [204.43/48.89]\n",
            "Episode 260 in 5.41 min. Expected total time for 1500 episodes: 31 min. [140.70/47.72]\n",
            "Episode 270 in 5.65 min. Expected total time for 1500 episodes: 31 min. [178.04/60.24]\n",
            "Episode 280 in 5.87 min. Expected total time for 1500 episodes: 32 min. [-44.04/72.03]\n",
            "Episode 290 in 6.11 min. Expected total time for 1500 episodes: 32 min. [189.66/83.76]\n",
            "Episode 300 in 6.36 min. Expected total time for 1500 episodes: 32 min. [195.98/90.62]\n",
            "Episode 310 in 6.68 min. Expected total time for 1500 episodes: 32 min. [222.43/79.90]\n",
            "Episode 320 in 6.88 min. Expected total time for 1500 episodes: 32 min. [238.37/79.84]\n",
            "Episode 330 in 7.11 min. Expected total time for 1500 episodes: 32 min. [213.27/78.02]\n",
            "Episode 340 in 7.34 min. Expected total time for 1500 episodes: 32 min. [124.73/88.38]\n",
            "Episode 350 in 7.58 min. Expected total time for 1500 episodes: 33 min. [239.96/104.05]\n",
            "Episode 360 in 7.80 min. Expected total time for 1500 episodes: 33 min. [157.12/119.52]\n",
            "Episode 370 in 8.04 min. Expected total time for 1500 episodes: 33 min. [-81.68/125.33]\n",
            "Episode 380 in 8.22 min. Expected total time for 1500 episodes: 33 min. [42.34/128.77]\n",
            "Episode 390 in 8.44 min. Expected total time for 1500 episodes: 33 min. [244.95/138.89]\n",
            "Episode 400 in 8.65 min. Expected total time for 1500 episodes: 33 min. [153.11/147.99]\n",
            "Episode 410 in 8.81 min. Expected total time for 1500 episodes: 32 min. [210.68/160.65]\n",
            "Episode 420 in 9.03 min. Expected total time for 1500 episodes: 32 min. [56.05/170.04]\n",
            "Episode 430 in 9.22 min. Expected total time for 1500 episodes: 32 min. [223.41/178.30]\n",
            "Episode 440 in 9.44 min. Expected total time for 1500 episodes: 32 min. [249.61/178.02]\n",
            "Episode 450 in 9.64 min. Expected total time for 1500 episodes: 32 min. [213.35/180.93]\n",
            "Episode 460 in 9.82 min. Expected total time for 1500 episodes: 32 min. [-5.49/187.84]\n",
            "Episode 470 in 10.00 min. Expected total time for 1500 episodes: 32 min. [238.24/191.31]\n",
            "Episode 480 in 10.16 min. Expected total time for 1500 episodes: 32 min. [249.17/198.21]\n",
            "Episode 490 in 10.30 min. Expected total time for 1500 episodes: 32 min. [201.83/206.66]\n",
            "Episode 500 in 10.44 min. Expected total time for 1500 episodes: 31 min. [236.10/205.21]\n",
            "Episode 510 in 10.61 min. Expected total time for 1500 episodes: 31 min. [244.43/206.01]\n",
            "Episode 520 in 10.78 min. Expected total time for 1500 episodes: 31 min. [185.12/206.63]\n",
            "Episode 530 in 10.91 min. Expected total time for 1500 episodes: 31 min. [260.67/209.86]\n",
            "Episode 540 in 11.07 min. Expected total time for 1500 episodes: 31 min. [281.18/216.07]\n",
            "Episode 550 in 11.22 min. Expected total time for 1500 episodes: 31 min. [245.09/221.28]\n",
            "Episode 560 in 11.37 min. Expected total time for 1500 episodes: 30 min. [215.03/220.76]\n",
            "Episode 570 in 11.53 min. Expected total time for 1500 episodes: 30 min. [296.23/225.96]\n",
            "Episode 580 in 11.70 min. Expected total time for 1500 episodes: 30 min. [264.42/226.41]\n",
            "Episode 590 in 11.91 min. Expected total time for 1500 episodes: 30 min. [179.45/221.27]\n",
            "Episode 600 in 12.08 min. Expected total time for 1500 episodes: 30 min. [232.28/226.34]\n",
            "Episode 610 in 12.27 min. Expected total time for 1500 episodes: 30 min. [250.40/230.04]\n",
            "Episode 620 in 12.43 min. Expected total time for 1500 episodes: 30 min. [-99.41/223.69]\n",
            "Episode 630 in 12.55 min. Expected total time for 1500 episodes: 30 min. [271.21/221.18]\n",
            "Episode 640 in 12.69 min. Expected total time for 1500 episodes: 30 min. [195.99/221.08]\n",
            "Episode 650 in 12.84 min. Expected total time for 1500 episodes: 30 min. [250.57/221.00]\n",
            "Episode 660 in 12.98 min. Expected total time for 1500 episodes: 30 min. [280.79/224.25]\n",
            "Episode 670 in 13.12 min. Expected total time for 1500 episodes: 29 min. [249.77/227.38]\n",
            "Episode 680 in 13.25 min. Expected total time for 1500 episodes: 29 min. [276.23/228.75]\n",
            "Episode 690 in 13.43 min. Expected total time for 1500 episodes: 29 min. [284.70/233.42]\n",
            "Episode 700 in 13.62 min. Expected total time for 1500 episodes: 29 min. [116.22/231.85]\n",
            "Episode 710 in 13.76 min. Expected total time for 1500 episodes: 29 min. [204.42/232.97]\n",
            "Episode 720 in 13.91 min. Expected total time for 1500 episodes: 29 min. [242.80/235.84]\n",
            "Episode 730 in 14.08 min. Expected total time for 1500 episodes: 29 min. [215.88/242.87]\n",
            "Episode 740 in 14.23 min. Expected total time for 1500 episodes: 29 min. [191.11/239.42]\n",
            "Episode 750 in 14.41 min. Expected total time for 1500 episodes: 29 min. [252.36/238.59]\n",
            "Episode 760 in 14.57 min. Expected total time for 1500 episodes: 29 min. [-8.94/233.47]\n",
            "Episode 770 in 14.72 min. Expected total time for 1500 episodes: 29 min. [243.18/231.43]\n",
            "Episode 780 in 14.86 min. Expected total time for 1500 episodes: 29 min. [191.11/226.75]\n",
            "Episode 790 in 15.02 min. Expected total time for 1500 episodes: 29 min. [268.41/227.48]\n",
            "Episode 800 in 15.16 min. Expected total time for 1500 episodes: 28 min. [242.23/224.90]\n",
            "Episode 810 in 15.31 min. Expected total time for 1500 episodes: 28 min. [284.11/227.87]\n",
            "Episode 820 in 15.42 min. Expected total time for 1500 episodes: 28 min. [298.41/224.98]\n",
            "Episode 830 in 15.54 min. Expected total time for 1500 episodes: 28 min. [235.36/227.88]\n",
            "Episode 840 in 15.64 min. Expected total time for 1500 episodes: 28 min. [231.75/231.75]\n",
            "Episode 850 in 15.78 min. Expected total time for 1500 episodes: 28 min. [244.24/234.04]\n",
            "Episode 860 in 15.89 min. Expected total time for 1500 episodes: 28 min. [279.98/236.08]\n",
            "Episode 870 in 16.03 min. Expected total time for 1500 episodes: 28 min. [213.83/238.30]\n",
            "Episode 880 in 16.18 min. Expected total time for 1500 episodes: 28 min. [195.61/239.85]\n",
            "Episode 890 in 16.31 min. Expected total time for 1500 episodes: 28 min. [251.13/235.29]\n",
            "Episode 900 in 16.45 min. Expected total time for 1500 episodes: 27 min. [238.92/234.33]\n",
            "Episode 910 in 16.59 min. Expected total time for 1500 episodes: 27 min. [240.39/234.72]\n",
            "Episode 920 in 16.70 min. Expected total time for 1500 episodes: 27 min. [249.02/238.73]\n",
            "Episode 930 in 16.84 min. Expected total time for 1500 episodes: 27 min. [274.51/231.83]\n",
            "Episode 940 in 16.94 min. Expected total time for 1500 episodes: 27 min. [229.83/231.74]\n",
            "Episode 950 in 17.04 min. Expected total time for 1500 episodes: 27 min. [288.69/234.06]\n",
            "Episode 960 in 17.13 min. Expected total time for 1500 episodes: 27 min. [270.16/235.44]\n",
            "Episode 970 in 17.24 min. Expected total time for 1500 episodes: 27 min. [247.26/236.45]\n",
            "Episode 980 in 17.34 min. Expected total time for 1500 episodes: 27 min. [278.31/236.42]\n",
            "Episode 990 in 17.43 min. Expected total time for 1500 episodes: 26 min. [232.89/239.88]\n",
            "Episode 1000 in 17.52 min. Expected total time for 1500 episodes: 26 min. [267.33/237.66]\n",
            "Episode 1010 in 17.60 min. Expected total time for 1500 episodes: 26 min. [247.23/229.50]\n",
            "Episode 1020 in 17.70 min. Expected total time for 1500 episodes: 26 min. [284.01/229.08]\n",
            "Episode 1030 in 17.78 min. Expected total time for 1500 episodes: 26 min. [289.26/229.97]\n",
            "Episode 1040 in 17.89 min. Expected total time for 1500 episodes: 26 min. [273.63/227.53]\n",
            "Episode 1050 in 17.99 min. Expected total time for 1500 episodes: 26 min. [256.50/223.92]\n",
            "Episode 1060 in 18.13 min. Expected total time for 1500 episodes: 26 min. [266.37/222.44]\n",
            "Episode 1070 in 18.27 min. Expected total time for 1500 episodes: 26 min. [187.58/220.63]\n",
            "Episode 1080 in 18.39 min. Expected total time for 1500 episodes: 26 min. [196.10/222.53]\n",
            "Episode 1090 in 18.52 min. Expected total time for 1500 episodes: 26 min. [-280.25/219.24]\n",
            "Episode 1100 in 18.74 min. Expected total time for 1500 episodes: 26 min. [-43.38/212.62]\n",
            "Episode 1110 in 18.89 min. Expected total time for 1500 episodes: 26 min. [223.45/217.18]\n",
            "Episode 1120 in 19.01 min. Expected total time for 1500 episodes: 25 min. [266.51/220.04]\n",
            "Episode 1130 in 19.10 min. Expected total time for 1500 episodes: 25 min. [280.10/227.06]\n",
            "Episode 1140 in 19.20 min. Expected total time for 1500 episodes: 25 min. [281.65/230.33]\n",
            "Episode 1150 in 19.29 min. Expected total time for 1500 episodes: 25 min. [276.91/234.01]\n",
            "Episode 1160 in 19.38 min. Expected total time for 1500 episodes: 25 min. [263.53/235.58]\n",
            "Episode 1170 in 19.47 min. Expected total time for 1500 episodes: 25 min. [253.26/237.21]\n",
            "Episode 1180 in 19.58 min. Expected total time for 1500 episodes: 25 min. [270.76/239.61]\n",
            "Episode 1190 in 19.67 min. Expected total time for 1500 episodes: 25 min. [232.49/243.04]\n",
            "Episode 1200 in 19.77 min. Expected total time for 1500 episodes: 25 min. [242.21/259.62]\n",
            "Episode 1210 in 19.86 min. Expected total time for 1500 episodes: 25 min. [264.08/267.92]\n",
            "Episode 1220 in 19.97 min. Expected total time for 1500 episodes: 25 min. [252.53/268.62]\n",
            "Episode 1230 in 20.07 min. Expected total time for 1500 episodes: 24 min. [262.24/266.71]\n",
            "Episode 1240 in 20.18 min. Expected total time for 1500 episodes: 24 min. [255.26/266.66]\n",
            "Episode 1250 in 20.28 min. Expected total time for 1500 episodes: 24 min. [238.76/266.10]\n",
            "Episode 1260 in 20.36 min. Expected total time for 1500 episodes: 24 min. [254.21/266.68]\n",
            "Episode 1270 in 20.46 min. Expected total time for 1500 episodes: 24 min. [243.86/266.56]\n",
            "Episode 1280 in 20.55 min. Expected total time for 1500 episodes: 24 min. [274.98/267.66]\n",
            "Episode 1290 in 20.65 min. Expected total time for 1500 episodes: 24 min. [245.49/267.18]\n",
            "Episode 1300 in 20.74 min. Expected total time for 1500 episodes: 24 min. [261.76/268.35]\n",
            "Episode 1310 in 20.83 min. Expected total time for 1500 episodes: 24 min. [296.49/267.82]\n",
            "Episode 1320 in 20.95 min. Expected total time for 1500 episodes: 24 min. [280.87/264.15]\n",
            "Episode 1330 in 21.05 min. Expected total time for 1500 episodes: 24 min. [271.12/266.34]\n",
            "Episode 1340 in 21.13 min. Expected total time for 1500 episodes: 24 min. [237.16/267.18]\n",
            "Episode 1350 in 21.20 min. Expected total time for 1500 episodes: 24 min. [252.27/266.32]\n",
            "Episode 1360 in 21.30 min. Expected total time for 1500 episodes: 24 min. [258.67/267.31]\n",
            "Episode 1370 in 21.37 min. Expected total time for 1500 episodes: 23 min. [241.16/266.98]\n",
            "Episode 1380 in 21.46 min. Expected total time for 1500 episodes: 23 min. [252.17/262.32]\n",
            "Episode 1390 in 21.54 min. Expected total time for 1500 episodes: 23 min. [277.13/262.65]\n",
            "Episode 1400 in 21.62 min. Expected total time for 1500 episodes: 23 min. [251.45/263.41]\n",
            "Episode 1410 in 21.70 min. Expected total time for 1500 episodes: 23 min. [278.19/263.40]\n",
            "Episode 1420 in 21.82 min. Expected total time for 1500 episodes: 23 min. [242.62/266.44]\n",
            "Episode 1430 in 21.94 min. Expected total time for 1500 episodes: 23 min. [226.83/265.48]\n",
            "Episode 1440 in 22.03 min. Expected total time for 1500 episodes: 23 min. [281.80/263.48]\n",
            "Episode 1450 in 22.14 min. Expected total time for 1500 episodes: 23 min. [270.89/264.69]\n",
            "Episode 1460 in 22.23 min. Expected total time for 1500 episodes: 23 min. [252.70/262.36]\n",
            "Episode 1470 in 22.34 min. Expected total time for 1500 episodes: 23 min. [244.17/261.43]\n",
            "Episode 1480 in 22.43 min. Expected total time for 1500 episodes: 23 min. [255.28/264.87]\n",
            "Episode 1490 in 22.54 min. Expected total time for 1500 episodes: 23 min. [206.65/264.62]\n",
            "Episode 1500 in 22.62 min. Expected total time for 1500 episodes: 23 min. [252.61/261.69]\n"
          ]
        }
      ],
      "source": [
        "# Uncomment to train\n",
        "agent = train_agent(n_episodes=1500, load_latest_model=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e596f509-6b4a-4ef5-b8f6-aae925b3d279",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-07T21:22:23.590427Z",
          "iopub.status.busy": "2023-02-07T21:22:23.590125Z",
          "iopub.status.idle": "2023-02-07T21:29:30.269658Z",
          "shell.execute_reply": "2023-02-07T21:29:30.269067Z",
          "shell.execute_reply.started": "2023-02-07T21:22:23.590411Z"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "e596f509-6b4a-4ef5-b8f6-aae925b3d279",
        "outputId": "279d55cf-3a86-4414-e5cd-50f7977d1eed"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualize the model\n",
        "import gymnasium as gym\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Set path to the model to visualize\n",
        "model_to_animate = '/content/ddqn_torch_model.h5'\n",
        "\n",
        "def animate_model(name, atype='single'):\n",
        "    env = gym.make(\"LunarLander-v2\", render_mode=\"rgb_array\")\n",
        "    agent = DoubleQAgent(gamma=0.99, epsilon=0.0, lr=0.0005, mem_size=200000, batch_size=64, epsilon_end=0.01)\n",
        "    agent.load_saved_model(name)\n",
        "    state, info = env.reset(seed=12)\n",
        "    for _ in range(5):\n",
        "        terminated = False\n",
        "        truncated = False\n",
        "        while not (terminated or truncated):\n",
        "            action = agent.choose_action(state)\n",
        "            new_state, reward, terminated, truncated, info = env.step(action)\n",
        "            state = new_state\n",
        "            clear_output(wait=True)\n",
        "            plt.imshow( env.render() )\n",
        "            plt.show()\n",
        "        state = env.reset()[0]\n",
        "    env.close()\n",
        "animate_model(model_to_animate, atype='double')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results\n",
        "\n",
        "* An Episode is a single run from initial state to final state. The model or agent was trained on 1500 episode.\n",
        "\n",
        "* The goal is said to be achieved when 200 points is reached. At 310 episode the 200 points was reached and first time goal was reached.\n",
        "\n",
        "* 5 episodes are replayed after the model is saved and used to run the experiment and in 4 episodes the satellite landed on the right spot.\n",
        "\n",
        "* So there is a 80% success rate for the trained model to land on the right spot\n",
        "\n",
        "* The implemented solution relies on three particular hyperparameters that had to be carefully selected to achieve successful results: the learning rate (α) used by the DNN implementation, the discount factor (γ = 0.99) of future rewards, and the decay rate of ε (ε-decay) to establish proper exploitation versus exploration balance."
      ],
      "metadata": {
        "id": "H4lYCWJOmt6Y"
      },
      "id": "H4lYCWJOmt6Y"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}